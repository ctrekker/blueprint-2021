{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "touched-modeling",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa as librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interracial-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_audio = keras.Input(shape =(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(16,(3,3), activation ='relu', padding = 'same')(input_audio)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(8,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(8,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "encoded = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "\n",
    "x = layers.Conv2D(8,(3,3), activation ='relu', padding = 'same')(encoded)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(8,(3,3), activation ='relu', padding = 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(16,(3,3), activation = 'relu')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "decoded = layers.Conv2D(1,(3,3), activation = 'sigmoid', padding = 'same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_audio, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparative-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = keras.Model(input_audio, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "harmful-catholic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.summary()\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suited-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designing-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test,_) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "x_train = np.reshape(x_train, (len(x_train),28,28,1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28,28,1))\n",
    "y_train = np.copy(x_train)\n",
    "x_train += np.random.rand(*x_train.shape)*.7\n",
    "x_train = np.minimum(x_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "isolated-terrain",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 21s 43ms/step - loss: 0.3800 - val_loss: 0.3388\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1875 - val_loss: 0.4519\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1692 - val_loss: 0.5503\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.1597 - val_loss: 0.5458\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1543 - val_loss: 0.4936\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1506 - val_loss: 0.5134\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.1471 - val_loss: 0.4662\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1442 - val_loss: 0.4482\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1420 - val_loss: 0.4036\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.1398 - val_loss: 0.4058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8781aabe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "autoencoder.fit(x_train, y_train, epochs = 10, batch_size=128, shuffle=True, validation_data = (x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "boring-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_audio = autoencoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ruled-syndication",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize = (20,6))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(encoded.predict(np.array([x_train[i]])).reshape(16, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "#     ax = plt.subplot(2,n,i+1+n)\n",
    "#     plt.imshow(decoded_audio[i].reshape(28,28))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sporting-console",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.predict(np.array([x_train[i]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "forbidden-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[i].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
